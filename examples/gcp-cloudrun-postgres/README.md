# OPR GCP Server

Creates an OPR server in Google Cloud Platform. This OPR server uses a number of GCP services:

- Cloud Storage - for storage and retrieval of encryption keys
- Cloud SQL (Postgres) - for offer storage
- Cloud Run - to run the server

## Pre-requisites

1. Install the gcloud CLI according to the instructions at https://cloud.google.com/sdk/docs/install
2. Install docker according to the instructions at https://docs.docker.com/engine/install/

## Set up the GCP Project

It can be quite a chore to set up a GCP project, but it's worth it.

### 1. Create the GCP Project

Go to https://console.cloud.google.com/projectcreate

Give it any name you'd like, but look carefully at the project id that appears under the name you type in. That project id is the real identifier for your project. If the project id is different from the project name you chose, it means your project name is already in use, so Google Cloud is autogenerating a new unique name for you. You might want to pick a different name if this is happening, since the autogenerated ids can be hard to remember.

It might take a while to create the project. Once it's built, make sure to select the project in the dropdown at the top of the screen.

### 2. Enable Billing

Many of the Google Cloud Platform APIs we use in this example require billing to be set up. Don't worry, you have $300 worth of free GCP quota. Enable billing at:

https://console.cloud.google.com/billing

### 3. Enable APIs

Enable the following APIs for your project:

1. [Cloud Run API](https://console.cloud.google.com/apis/library/run.googleapis.com)
2. [Compute Engine API](https://console.cloud.google.com/apis/library/compute.googleapis.com) (we're not using this API directly, but it's required for Cloud SQL)
3. [Cloud SQL Admin API](https://console.cloud.google.com/apis/library/sqladmin.googleapis.com)
4. [Artifact Registry API](https://console.cloud.google.com/apis/api/artifactregistry.googleapis.com)
5. [Cloud Scheduler API](https://console.cloud.google.com/apis/library/cloudscheduler.googleapis.com)

NOTE: If you clicked the links above, double-check that the correct Google Cloud project is selected in the dropdown at the top of the screen. If you have many Google Cloud projects, the wrong project might be selected initially.

### 4. Set up Cloud SQL

Go to https://console.cloud.google.com/sql/instances/create;engine=PostgreSQL to set up a new Cloud SQL Postgres database. Fill in the form as follows:

1. **Instance ID**: `example-server-database-instance`
2. **Password**: Choose a password, or click autogenerate. _Remember what you picked_. We'll need this value later.
3. **Database Version**: Pick the latest one, which should be autoselected already.
4. **Choose a configuration to start with**: `Development`
   - It's cheaper, and this is just a demo. In real life, use a production server.
5. **Region**: `us-central-1`
6. **Zonal availability**: `Single Zone`
   - Again, it's cheaper for a demo. A real server would want the "Multiple Zones" offer.
7. Click the "Create Instance" button.

Settle in. Watch some videos online. Maybe start a meditation practice. Some day, when your desire to run this server is but a distant memory, the provisioning process, like all things, must come to an end. This step took between 8 and 10 minutes for us.

_Warning_: It's not expensive to run Cloud SQL for a few hours, but the monthly costs can add up, even if you aren't actively using your database. Make sure to shut down this project when you're done so the costs don't add up.

### 5. Create a service account

Go to https://console.cloud.google.com/iam-admin/serviceaccounts/create to create a new service account. Fill out the form as follows:

1. **Service account name** - `example-server-agent`
2. **Service account id** - `example-server-agent`
3. Click **Create and Continue**
4. In the **Grant this service account access to project** section, grant the following roles:
   1. Cloud SQL Client
   2. Cloud Run Invoker
5. Click **Done**

### 6. Create a Cloud Storage Bucket

Go to https://console.cloud.google.com/storage/create-bucket to create a Cloud Storage bucket. Fill in the form as follows:

1. **Bucket name**: `YOUR_PROJECT_ID-config`
    - Replace YOUR_PROJECT_ID with your project id
2. Click **Continue**
3. **Location type** - `Region`
4. **Region**: Pick a region near you
5. Click **Continue**
6. **Choose a default storage class for your data**: `Standard`
7. Click **Continue**
8. **Prevent public access to objects**: `Enforce public access protection on this bucket`
9. **Access Control** - `Uniform`
10. Click the **Create** button at the bottom
11. Click **Confirm** on the popup window explaining public access protections.

A bucket configuration page will appear. On that page, fill in the form as follows:

1. Click the **Permissions** tab.
2. Click the **Grant access** button.
3. **New principals** - `example-server-agent@YOUR_PROJECT_ID.iam.gserviceaccount.com`
    - Replace YOUR_PROJECT_ID with your project's id
4. **Role** - `Storage object viewer`
    - Make sure to choose "Storage object viewer", NOT "Storage Legacy Object Reader"
5. Click **Save**

### 7. Generate and upload encryption keys

In a terminal, `cd` to the gcp-cloudrun-postgres directory. Then run:

```console
./generate_keys.sh YOUR_PROJECT_ID
```

Replace YOUR_PROJECT_ID with your project id.

This will generate encryption keys and upload them to your cloud storage bucket.


### 8. Set up authentication for Google Cloud Container Registry

From a terminal, run:

```console
gcloud auth login
gcloud auth configure-docker
```

Note: Depending on how you have docker set up, you may need to run docker as root (using `sudo docker` instead of `docker`). If you need to run docker as root, run `sudo gcloud auth configure-docker` to make sure your credentials are available to docker commands.

### 9. Build the server image

From a terminal, build the server by running the command:

```console
docker build --no-cache --platform linux/amd64 -t gcr.io/YOUR_PROJECT_ID/example-server .
```

Replace `YOUR_PROJECT_ID` above with the id of your Google Cloud project.

### 10. Upload the Docker image to Artifact Registry

From a terminal, run the server by running the command:

```console
docker push gcr.io/YOUR_PROJECT_ID/example-server
```
Replace `YOUR_PROJECT_ID` above with the id of your Google Cloud project.

### 11. Create a Cloud Run service

Go to https://console.cloud.google.com/run/create to create a new Cloud Run service. Fill in the form as follows:

1. Pick **Deploy one revision from a container image**
2. Click **Select** in the **Container image url** field
3. Expand **gcr.io/YOUR_PROJECT_ID/example-server** in the flyout menu that appears
4. Pick the entry marked **latest** and click the **Select** button.
5. **Service name**: `example-server`
6. **Region**: `us-central-1`
7. **CPU Allocation and Pricing**: Pick `CPU is only allocated during request processing`
8. **Autoscaling - Minimum Number of Instances**: `0`
9. **Autoscaling - Maximum Number of Instances**: `100`
10. **Ingress**: `Allow all traffic`
11. **Authentication**: `Allow unauthenticated invocations`
12. Expand the section labeled **Container, Connections, Security**
13. Scroll down to Environment Variables. Add the following name/value pairs:
    1.  `DB_HOST`: `/cloudsql/YOUR_PROJECT_ID:us-central1:example-server-database-instance`
        - Replace YOUR_PROJECT_ID with your project's id  
    2.  `DB_USER`: `postgres`
    3.  `DB_PASSWORD`: The database password you picked earlier
        - NOTE: In a non-demo deployment, you'd want to use a Cloud Secret for a value like this, but we're doing it in a regular environment variable for simplicity.
    4.  `DB_NAME`: `postgres`
    5.  `OPR_SERVICE_ACCOUNT`: `example-server-agent@YOUR_PROJECT_ID.iam.gserviceaccount.com`
        - Replace YOUR_PROJECT_ID with your project's id
    6. `GCS_PUBLIC_KEYS_PATH`: `gs://YOUR_PROJECT_ID-config/publickeys`
        - Replace YOUR_PROJECT_ID with your project's id
    7. `GCS_PRIVATE_KEY_PATH`: `gs://YOUR_PROJECT_ID-config/opr-private-key.json`
        - Replace YOUR_PROJECT_ID with your project's id
-   8. `DB_SYNCHRONIZE_MAY_CAUSE_DATA_LOSS` - `yes`
-       - This flag will build database tables if they don't exist. It lowers performance and may cause data loss if you change your schemas, but this is the easiest way to build the initial tables we need. We'll remove it later.
    9. `OPR_HOSTNAME` - `https://fakehost.org`
        - We're going to come back to this, but we need a placeholder value for now.
14. Click the **Connections** tab
15. Under **Cloud SQL Connections** click **Add Connection**
16. Choose `YOUR_PROJECT_ID:us-central1:example-server-database-instance` from the dropdown
    - In the dropdown, YOUR_PROJECT_ID will be replaced with your project's id
17. Click **Create**

After a few minutes (4 for us), your Cloud Run service will be created. When it's done, there will be a small URL near the top of the screen for your new service. Copy that URL to the clipboard. We're going to call this URL YOUR_SERVICE_URL in subsequent steps.

Now:

1. Click the **Edit and Deploy New Revision** button at the top of the screen.
2. Replace the value of the `OPR_HOSTNAME` env variable with the Cloud Run service url you just copied to the clipboard.
3. Click **Deploy**

Wait a few more minutes.

Now, at long last, visit: YOUR_SERVICE_URL/org.json

You should see an org config file! It's running!

Go to YOUR_SERVICE_URL/alloffers

You should see an empty JSON array, because your service has no offers in it. Let's fix that.

### 12. Set up Cloud Scheduler

Go to https://console.cloud.google.com/cloudscheduler/jobs/new to set up a new Cloud Scheduler job. Fill in the form as follows:

1. **Name**:`example-server-ingestor`
2. **Region**: Pick a region near you
3. **Frequency**: `*/3 * * * *`
    - That means "run this every 3 minutes"
4. **Timezone**: `Greenwich Mean Time`
    - NOTE: The selector here doesn't work very well. We recommend you type `World` into the **Search by Country** text box, then click **World** in the list box, then click `Greenwich Mean Time`. Mysteriously, typing GMT into this text box doesn't work. Why?
5. Click **Continue**
6. **Target Type**: `HTTP`
7. **URL**: `YOUR_SERVICE_URL/ingest`
   - Replace YOUR_SERVICE_URL with the service URL you copied earlier
8. **HTTP Method**: `POST`
9. **Auth Header**: `Add OIDC Token`
10. **Service Account**: `example-server-agent`
11. **Audience**: leave blank
12. Click the **Create** button

_Warning_: Once you start Cloud Scheduler, your project will be using computing and database resources every 3 minutes. Make sure to shut your project down when you're done with this demo so you don't end up incurring lots of fees over the months and years this could keep running.

A job list will appear with your new Cloud Scheduler job. On the far right is a column labeled "Actions". Click the 3 dot icon under actions, and pick "Force job run."

Now go to YOUR_SERVICE_URL/alloffers

There's an offer there now!

### 13. Cleaning Up the Service

If you'd like the service to run faster, go back to your cloud run service and delete the `DB_SYNCHRONIZE_MAY_CAUSE_DATA_LOSS` environment variable. We don't need it now that the database structure is in place. Removing it will speed up every database request.

### 14. Deleting the project (important!!!)

Once you're tired of your little demo server, make sure to delete the project. Since we have Cloud Scheduler running every 3 minutes, this project will eventually start costing you money if you don't shut it down.

Go to https://console.cloud.google.com/iam-admin/settings to see the project settings. Then:

1. Click the **Shutdown** button.
2. Type the project name into the field to confirm deletion.
3. Click **Ok**
